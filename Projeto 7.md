# Projeto 7 ‚Äî Valida√ß√£o Cruzada (Cross-Validation) e Robustez de Modelos

---

## üìö Explica√ß√£o do Curso
Este projeto foi desenvolvido como parte do curso de Cientista de Dados da EBAC, focando na aplica√ß√£o de t√©cnicas essenciais para garantir a **robustez e a generaliza√ß√£o** dos modelos de Machine Learning. O projeto utiliza um dataset de vari√°veis ambientais (Temperatura, Umidade, CO2, etc.) para a **previs√£o bin√°ria de alarme de inc√™ndio** (`Fire Alarm`), com o objetivo de testar o modelo de forma imparcial atrav√©s da Valida√ß√£o Cruzada.

---

## üéØ Objetivos
O principal objetivo deste projeto √© consolidar as habilidades de valida√ß√£o de modelos e garantir sua estabilidade:

* **Valida√ß√£o Cruzada (k-fold):** Aplicar a t√©cnica de Valida√ß√£o Cruzada (*k-fold*) para avaliar o desempenho de um modelo de classifica√ß√£o (Random Forest) de forma imparcial.
* **Garantir Generaliza√ß√£o:** Entender a import√¢ncia da valida√ß√£o cruzada para garantir que o modelo n√£o esteja "viciado" em um √∫nico conjunto de teste.
* **An√°lise de Estabilidade:** Analisar a varia√ß√£o da m√©trica (Acur√°cia) entre os diferentes *folds* e calcular a pontua√ß√£o m√©dia final, provando a robustez do modelo.
* **Otimiza√ß√£o de Hiperpar√¢metros:** Utilizar o `RandomizedSearchCV` para buscar os melhores hiperpar√¢metros, seguido pela valida√ß√£o final com o K-Fold.

---

## üíª Tecnologias Usadas
* **Linguagem:** Python
* **Algoritmo Principal:** Random Forest Classifier.
* **T√©cnica de Valida√ß√£o:** K-Fold Cross-Validation.
* **Bibliotecas Principais:** Pandas, Scikit-learn (RandomForestClassifier, KFold, cross_val_score), `RandomizedSearchCV`.
* **Ambiente:** Jupyter Notebook.

---

## üìà Principais An√°lises Realizadas
O projeto focou nas seguintes etapas e an√°lises t√©cnicas:

* **Pr√©-processamento Inicial:** Carregamento da base de dados e checagem da aus√™ncia de valores nulos (missing values).
* **Otimiza√ß√£o de Hiperpar√¢metros:** Uso do `RandomizedSearchCV` para encontrar a melhor combina√ß√£o de par√¢metros para o Random Forest na base de treino.
* **Valida√ß√£o Cruzada (5-fold):** Divis√£o do *dataset* utilizando o `KFold` (com 5 *folds*), garantindo que o modelo seja treinado e testado em diferentes subconjuntos da base.
* **C√°lculo de Robustez:** Aplica√ß√£o do modelo em cada uma das divis√µes e c√°lculo da **Acur√°cia M√©dia** entre todos os *folds*, representando a performance est√°vel do modelo.
* **An√°lise de Desempenho:** Compara√ß√£o da pontua√ß√£o m√©dia do *k-fold* com a acur√°cia de uma √∫nica divis√£o de teste/treino.

---

## ‚ú® Insights Chave (Valor de Neg√≥cio e Conclus√£o)

As conclus√µes deste projeto refor√ßam a import√¢ncia da metodologia na constru√ß√£o de Machine Learning:

* **Pr√°tica Obrigat√≥ria:** O exerc√≠cio validou a **Valida√ß√£o Cruzada** como uma pr√°tica obrigat√≥ria na constru√ß√£o de modelos robustos, demonstrando que a acur√°cia m√©dia do *k-fold* √© a m√©trica mais confi√°vel.
* **Modelo de Alta Confian√ßa:** O modelo de Random Forest apresentou um desempenho consistentemente alto (com acur√°cia m√©dia de aproximadamente **98,87%**) entre todos os *folds*, provando sua alta capacidade de generaliza√ß√£o e evitando o risco de *overfitting*.
* **Relev√¢ncia para IoT:** O resultado √© um modelo preditivo de alta confiabilidade, pronto para ser aplicado em ambientes de IoT (Internet das Coisas) para sistemas de alerta de inc√™ndio, onde a estabilidade da previs√£o √© vital.